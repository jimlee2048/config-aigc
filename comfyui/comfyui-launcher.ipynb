{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ComfyUI Launcher"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import time\n",
        "import requests\n",
        "import toml\n",
        "import subprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# config\n",
        "## path\n",
        "WORKSPACE_PATH = os.path.join('..', 'workspace')\n",
        "MODEL_PATH = os.path.join(WORKSPACE_PATH, 'models')\n",
        "APP_PATH = os.path.join(WORKSPACE_PATH, 'comfyui')\n",
        "\n",
        "## custom nodes init\n",
        "CUSTOM_NODES_CONFIG = 'comfyui-custom_nodes.toml'\n",
        "CUSTOM_NODES_INSTALL_REQ = False\n",
        "\n",
        "## model downloading\n",
        "MODELS_DOWNLOAD = False\n",
        "MODELS_CONFIG = 'comfyui-models.toml'\n",
        "MODELS_INCLUDE_CATEGORY = []\n",
        "\n",
        "## app launch\n",
        "AUTO_UPDATE = False\n",
        "LAUNCH_CLI_ARGS = [\n",
        "    \"--listen 127.0.0.1\",\n",
        "    \"--port 8080\",\n",
        "    \"--disable-auto-launch\"\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# debug\n",
        "## debug env\n",
        "WORKSPACE_PATH = os.path.join('..', 'workspace', 'test')\n",
        "CUSTOM_NODES_INSTALL_REQ = True\n",
        "MODELS_DOWNLOAD = True\n",
        "MODELS_INCLUDE_CATEGORY = ['sd15']\n",
        "AUTO_UPDATE = True\n",
        "\n",
        "## use absolute path\n",
        "WORKSPACE_PATH = os.path.abspath(WORKSPACE_PATH)\n",
        "MODEL_PATH = os.path.abspath(MODEL_PATH)\n",
        "APP_PATH = os.path.abspath(APP_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# global utils\n",
        "def is_dir_empty(path):\n",
        "    return len(os.listdir(path)) == 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# set proxy\n",
        "\n",
        "#!export HTTP_PROXY=http://host.docker.internal:1081\n",
        "#!export HTTPS_PROXY=$HTTP_PROXY\n",
        "#!export http_proxy=$HTTP_PROXY\n",
        "#!export https_proxy=$HTTP_PROXY\n",
        "#!export NO_PROXY=\"localhost,*.local,*.internal,[::1],fd00::/7,\n",
        "#10.0.0.0/8,127.0.0.0/8,169.254.0.0/16,172.16.0.0/12,192.168.0.0/16,\n",
        "#10.*,127.*,169.254.*,172.16.*,172.17.*,172.18.*,172.19.*,172.20.*,\n",
        "#172.21.*,172.22.*,172.23.*,172.24.*,172.25.*,172.26.*,172.27.*,\n",
        "#172.28.*,172.29.*,172.30.*,172.31.*,172.32.*,192.168.*,\n",
        "#*.cn,ghproxy.com,*.ghproxy.com,ghproxy.org,*.ghproxy.org,\n",
        "#gh-proxy.com,*.gh-proxy.com,ghproxy.net,*.ghproxy.net\"\n",
        "#!export no_proxy=$NO_PROXY\n",
        "#!echo \"[INFO] Proxy set to $HTTP_PROXY\"\n",
        "\n",
        "# os.environ['HTTP_PROXY'] = 'http://host.docker.internal:1081'\n",
        "# os.environ['HTTPS_PROXY'] = os.environ['HTTP_PROXY']\n",
        "# os.environ['http_proxy'] = os.environ['HTTP_PROXY']\n",
        "# os.environ['https_proxy'] = os.environ['HTTP_PROXY']\n",
        "# os.environ['NO_PROXY'] = \"localhost,*.local,*.internal,[::1],fd00::/7,10.0.0.0/8,127.0.0.0/8,169.254.0.0/16,172.16.0.0/12,192.168.0.0/16,10.*,127.*,169.254.*,172.16.*,172.17.*,172.18.*,172.19.*,172.20.*,172.21.*,172.22.*,172.23.*,172.24.*,172.25.*,172.26.*,172.27.*,172.28.*,172.29.*,172.30.*,172.31.*,172.32.*,192.168.*,*.cn,ghproxy.com,*.ghproxy.com,ghproxy.org,*.ghproxy.org,gh-proxy.com,*.gh-proxy.com,ghproxy.net,*.ghproxy.net\"\n",
        "# os.environ['no_proxy'] = os.environ['NO_PROXY']\n",
        "# print(f\"üü° Proxy set to {os.environ['HTTP_PROXY']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# check if nvidia cuda is available\n",
        "def check_cuda():\n",
        "    try:\n",
        "        print(subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE, stderr=subprocess.PIPE).stdout.decode('utf-8'))\n",
        "        print(\"üü¢ nvidia cuda found\")        \n",
        "        return True\n",
        "    except FileNotFoundError:   \n",
        "        print(\"üü° nvidia cuda not found\")\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbbbbbbbbb"
      },
      "outputs": [],
      "source": [
        "# initialize comfyui\n",
        "print('üì¶ Start: initialize comfyui')\n",
        "try:\n",
        "    if os.path.exists(APP_PATH) and AUTO_UPDATE:\n",
        "        print(\"üîÑ Existed comfyui, checking updates...\")\n",
        "        update_result = subprocess.run(['git', 'pull'], cwd=APP_PATH, capture_output=True, text=True, check=True)\n",
        "        if 'Already up to date' in update_result.stdout:\n",
        "            print(\"üîÑ comfyui is already up to date!\")\n",
        "        else:\n",
        "            print(\"üîÑ comfyui is updated!\")\n",
        "    elif os.path.exists(APP_PATH):\n",
        "        print(\"üì¶ Existed comfyui, skip installation\")\n",
        "    else:\n",
        "        print('üì¶ Install: comfyui')\n",
        "        subprocess.run(['git', 'clone', 'https://github.com/comfyanonymous/ComfyUI.git', APP_PATH], check=True)\n",
        "        if check_cuda():\n",
        "            subprocess.run(['pip', 'install', 'xformers', '-r', os.path.join(APP_PATH, \"requirements.txt\")], cwd=APP_PATH, check=True)\n",
        "        else:\n",
        "            subprocess.run(['pip', 'install', '-r', os.path.join(APP_PATH, \"requirements.txt\")], cwd=APP_PATH, check=True)\n",
        "except Exception as e:\n",
        "    print(f\"üî¥ Error: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# downloader\n",
        "from tqdm import tqdm\n",
        "from urllib.parse import urlparse\n",
        "from cgi import parse_header\n",
        "\n",
        "def downloader(url, dir, filename=None, overwrite=False, timeout=30, max_retries=3, retry_interval=5):\n",
        "    print(f\"‚¨áÔ∏è Downloading: {url}\")\n",
        "    os.makedirs(dir, exist_ok=True)\n",
        "    retries = 0\n",
        "    download_path = None\n",
        "    while retries < max_retries:\n",
        "        try:\n",
        "            with requests.get(url, stream=True, timeout=timeout) as r:\n",
        "                r.raise_for_status()\n",
        "                if filename is None:\n",
        "                    content_disposition = r.headers.get('content-disposition')\n",
        "                    if content_disposition:\n",
        "                        _, params = parse_header(content_disposition)\n",
        "                        filename = params.get('filename')\n",
        "                    else:\n",
        "                        filename = os.path.basename(urlparse(url).path)\n",
        "                print(f\"‚¨áÔ∏è {filename} -> {dir}\")\n",
        "                download_path = os.path.join(dir,filename)\n",
        "                if os.path.exists(download_path) and overwrite == False:\n",
        "                    print(f\"üü° Existed, skip: {filename} -> {dir}\")\n",
        "                    return None\n",
        "                download_size = int(r.headers.get('content-length', 0))\n",
        "                progress_bar = tqdm(total=download_size, unit='iB', unit_scale=True)\n",
        "                with open(download_path, \"wb\") as f:\n",
        "                    for chunk in r.iter_content(chunk_size=8192):\n",
        "                        progress_bar.update(len(chunk))\n",
        "                        f.write(chunk)\n",
        "                progress_bar.close()\n",
        "                print(f\"üü¢ Downloaded: {filename} -> {dir}\")\n",
        "                return True\n",
        "        except Exception as e:\n",
        "            print(f\"üî¥ Error: {e}\")\n",
        "            retries += 1\n",
        "            print(f\"‚è≥ Retrying download, sleep {retry_interval}s... ({retries}/{max_retries})\")\n",
        "            time.sleep(retry_interval)\n",
        "    print(f\"üî¥ Failed to download: {url}\")\n",
        "    if download_path and os.path.exists(download_path):\n",
        "        os.remove(download_path)\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# aria2 downloader\n",
        "# be sure to install aria2 first\n",
        "# !apt-get install -y aria2\n",
        "# !aria2c --enable-rpc --rpc-listen-all=false --rpc-listen-port 6800 --dir=$MODEL_PATH --max-concurrent-downloads=5\n",
        "\n",
        "import aria2p\n",
        "\n",
        "def downloader_aria2(url, dir, filename=None, timeout=30, max_retries=3, retry_interval=5):\n",
        "    print(f\"‚¨áÔ∏è Downloading: {url}\")\n",
        "    os.makedirs(dir, exist_ok=True)\n",
        "    client = aria2p.Client(host=\"http://localhost\", port=6800)\n",
        "    api = aria2p.API(client)\n",
        "    retries = 0\n",
        "    while retries < max_retries:\n",
        "        try:\n",
        "            if filename is None:\n",
        "                download = api.add_uri(\n",
        "                    [url], options={\"dir\": dir, \"continue\": \"true\", \"timeout\": timeout})\n",
        "                filename = download.name\n",
        "            else:\n",
        "                download = api.add_uri([url], options=\n",
        "                    {\n",
        "                        \"dir\": dir, \n",
        "                        \"out\": filename, \n",
        "                        \"continue\": \"true\", \n",
        "                        \"timeout\": timeout\n",
        "                    })\n",
        "            while not download.is_complete:\n",
        "                download.update()\n",
        "                if download.error_message:\n",
        "                    raise Exception(download.error_message)\n",
        "        except Exception as e:\n",
        "            print(f\"üü° Error downloading file: {e}\")\n",
        "            retries += 1\n",
        "            print(f\"‚è≥ Retrying download, sleep {retry_interval}s... ({retries}/{max_retries})\")\n",
        "            time.sleep(retry_interval)\n",
        "    if retries >= max_retries:\n",
        "        print(f\"üî¥ Failed to download: {url}\")\n",
        "        return False\n",
        "    print(f\"üü¢ {filename} -> {dir}: downloaded.\")\n",
        "    return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def download_models(models_dict, model_path=MODEL_PATH, include_category=MODELS_INCLUDE_CATEGORY):\n",
        "    print(f\"‚¨áÔ∏è Start: downloads models to {model_path}\")\n",
        "    if include_category:\n",
        "        print(f\"üü° Include categories: {include_category}, will download these model categories only.\")\n",
        "    total_list = []\n",
        "    downloaded_list = []\n",
        "    skipped_list = []\n",
        "    error_list = []\n",
        "    for type_name, type in models_dict.items():\n",
        "        for model in type['items']:\n",
        "            if include_category and model.get('category') not in include_category:\n",
        "                print(f\"üü° Skipped: {model['url']}\")\n",
        "                skipped_list.append(model['url'])\n",
        "                continue\n",
        "            download_url = model['url']\n",
        "            total_list.append(download_url)\n",
        "            download_dir = os.path.join(model_path, model['dir'] or type['dir'] or os.path.join(type_name, model.get('category')))\n",
        "            download_filename = model.get('filename')\n",
        "            download_status = downloader(download_url, download_dir, download_filename)\n",
        "            if download_status:\n",
        "                downloaded_list.append(download_url)\n",
        "            elif download_status is None:\n",
        "                skipped_list.append(download_url)\n",
        "            else:\n",
        "                error_list.append(download_url)\n",
        "    total_counts = len(total_list)\n",
        "    downloaded_counts = len(downloaded_list)\n",
        "    skipped_counts = len(skipped_list)\n",
        "    error_counts = len(error_list)\n",
        "    print(f\"‚¨áÔ∏è Finished: downloads models to {model_path}\")\n",
        "    print(f\"üì¶ Total: {total_counts}\"\n",
        "          f\"\\nüü¢ Downloaded: {downloaded_counts}\"\n",
        "          f\"\\nüü° Skipped: {skipped_counts}\"\n",
        "          f\"\\nüî¥ Error: {error_counts}\")\n",
        "    if error_counts > 0:\n",
        "        for i in error_list:\n",
        "            print(f\"- {i}\")\n",
        "    return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# prepare models dir\n",
        "# !mkdir -p $MODEL_PATH/configs\n",
        "# !cp -rf $APP_PATH/models/configs/* $MODEL_PATH/configs\n",
        "# !rm -rf $APP_PATH/models\n",
        "# !ln -sf $MODEL_PATH $APP_PATH/models\n",
        "\n",
        "\n",
        "os.makedirs(os.path.join(MODEL_PATH, \"configs\"), exist_ok=True)\n",
        "if not os.path.islink(os.path.join(APP_PATH, \"models\")):\n",
        "    src = MODEL_PATH\n",
        "    dst = os.path.join(APP_PATH, \"models\")\n",
        "    if os.path.exists(os.path.join(dst, \"configs\")) and not is_dir_empty(dst) and not os.path.exists(os.path.join(src, \"configs\")):\n",
        "        shutil.copytree(os.path.join(dst, \"configs\"), os.path.join(src, \"configs\"), dirs_exist_ok=True)\n",
        "    shutil.rmtree(os.path.join(dst))\n",
        "    os.symlink(src, dst, target_is_directory=True)\n",
        "\n",
        "if MODELS_DOWNLOAD:\n",
        "    config_models = toml.load(MODELS_CONFIG)\n",
        "    models = config_models['models']\n",
        "    download_models(models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def init_custom_nodes(custom_nodes, install_requirements=CUSTOM_NODES_INSTALL_REQ, max_retries=3, retry_interval=5):\n",
        "    print(f\"üì¶ Start: initializing custom nodes\")\n",
        "    requirements_list = []\n",
        "    new_list = []\n",
        "    existing_list = []\n",
        "    updated_list = []\n",
        "    error_list = []\n",
        "    for cn in custom_nodes:\n",
        "        cn_url = cn['url']\n",
        "        cn_name = urlparse(cn_url).path.split('/')[-1].split('.')[0]\n",
        "        cn_path = os.path.join(APP_PATH, \"custom_nodes\", cn_name)\n",
        "        if len(os.listdir(cn_path)) == 1 and os.path.exists(os.path.join(cn_path, '.git')):\n",
        "            print(f\"üî¥ {cn_name}: custom nodes broken, will reinstall\")\n",
        "            shutil.rmtree(cn_path)\n",
        "        retries = 0\n",
        "        while retries < max_retries:\n",
        "            try:\n",
        "                if os.path.exists(cn_path) and not is_dir_empty(cn_path):\n",
        "                    print(f\"üü° {cn_name}: existed custom nodes.\")\n",
        "                    existing_list.append(cn_name)\n",
        "                    if AUTO_UPDATE:\n",
        "                        update_result = subprocess.run(['git', 'pull'], cwd=cn_path, capture_output=True, text=True, check=True)\n",
        "                        if 'Already up to date' in update_result.stdout:\n",
        "                            print(f\"üü° {cn_name}: custom nodes already up to date.\")\n",
        "                            break\n",
        "                        else:\n",
        "                            print(f\"üü¢ {cn_name}: custom nodes updated.\")\n",
        "                            updated_list.append(cn_name)\n",
        "                            break\n",
        "                else:\n",
        "                    print(f\"üü¢ {cn_name}: new custom nodes, cloning...\")\n",
        "                    subprocess.check_call(['git', 'clone', cn_url, cn_path])\n",
        "                    requirements_list + [\"-r\", os.path.join(cn_path, \"requirement.txt\")]\n",
        "                    new_list.append(cn_name)\n",
        "                    break\n",
        "            except Exception as e:\n",
        "                print(f\"üî¥ {cn_name}: error: {e}\")\n",
        "                retries += 1\n",
        "                print(f\"‚è≥ Retrying, sleep {retry_interval}s... ({retries}/{max_retries})\")\n",
        "                time.sleep(retry_interval)\n",
        "        if retries >= max_retries:\n",
        "            print(f\"üî¥ {cn_name}: failed to clone!\")\n",
        "            error_list.append(cn_name)\n",
        "            return False\n",
        "        \n",
        "    total_counts = len(custom_nodes)\n",
        "    existing_counts =len(existing_list)\n",
        "    new_counts = len(new_list)\n",
        "    error_counts = len(error_list)\n",
        "    print(f\"üì¶ Finished: initialize custom nodes\")\n",
        "    print(f\"üì¶ Total: {total_counts}\")\n",
        "    print(f\"üü° Existed: {existing_counts}\")\n",
        "    if AUTO_UPDATE:\n",
        "        updated = len(updated_list)\n",
        "        print(f\"üü¢ Updated: {updated}\")\n",
        "    print(f\"üü¢ New: {new_counts}\")\n",
        "    if new_counts > 0:\n",
        "        for i in new_list:\n",
        "            print(f\"- {i}\")\n",
        "    print(f\"üî¥ Error: {error_counts}\")\n",
        "    if error_counts > 0:\n",
        "        for i in error_list:\n",
        "            print(f\" - {i}\")\n",
        "\n",
        "    if install_requirements and requirements_list:\n",
        "        print(f\"üì¶ Try: pre-install new custom nodes requirements\")\n",
        "        install_requirements_command = [\"pip\", \"install\"] + requirements_list\n",
        "        try:\n",
        "            subprocess.check_call(install_requirements_command)\n",
        "        except Exception as e:\n",
        "            print(f\"üî¥ Error: {e}\")\n",
        "            return False\n",
        "        print(f\"üü¢ Success: pre-install new custom nodes requirements.\")\n",
        "\n",
        "    return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# initial comfyui custom_nodes\n",
        "config_custom_nodes = toml.load(CUSTOM_NODES_CONFIG)\n",
        "custom_nodes = config_custom_nodes['custom_nodes']\n",
        "custom_nodes_models = config_custom_nodes['models']\n",
        "# download custom_nodes from list\n",
        "init_custom_nodes(custom_nodes)\n",
        "download_models(custom_nodes_models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Launch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!cd $APP_PATH\n",
        "!python main.py {LAUNCH_CLI_ARGS}"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
